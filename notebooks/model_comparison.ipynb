{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Notebook\n",
    "\n",
    "This notebook orchestrates the training, prediction, and evaluation of various time series forecasting models on the energy consumption dataset. It includes:\n",
    "\n",
    "- Temporal Fusion Transformer (TFT)\n",
    "- N-BEATS\n",
    "- Informer\n",
    "- DeepAR\n",
    "\n",
    "The goal is to provide a comparative analysis of their performance based on common forecasting metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup and Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Ensure the virtual environment is activated (important for script execution)\n",
    "activate_this_file = os.path.join('.venv', 'Scripts', 'activate')\n",
    "if os.path.exists(activate_this_file):\n",
    "    # This is for internal consistency, subprocess calls will use the active env\n",
    "    # For Jupyter, typically the kernel is already running in the correct env\n",
    "    pass\n",
    "else:\n",
    "    print(\"Warning: Virtual environment activation script not found. Ensure your Jupyter kernel is running in the correct virtual environment.\")\n",
    "\n",
    "# Define paths and common variables\n",
    "DATA_PATH = 'composite_energy_data.csv'\n",
    "REGION = 'PJME_MW'\n",
    "CHECKPOINTS_DIR = 'checkpoints'\n",
    "MAX_EPOCHS = 5 # Use a small number for quick testing in notebook\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "if not os.path.exists(CHECKPOINTS_DIR):\n",
    "    os.makedirs(CHECKPOINTS_DIR)\n",
    "\n",
    "print(f\"Data Path: {DATA_PATH}\")\n",
    "print(f\"Region: {REGION}\")\n",
    "print(f\"Checkpoints Directory: {CHECKPOINTS_DIR}\")\n",
    "print(f\"Max Epochs for Training: {MAX_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loading and Preparation\n",
    "# We'll use the data loading functions from train_tft.py (they are common across models)\n",
    "from train_tft import load_and_prepare_data, create_datasets\n",
    "\n",
    "print(\"Loading and preparing data...\")\n",
    "df = load_and_prepare_data(data_path=DATA_PATH, region=REGION)\n",
    "training_dataset, validation_dataset, test_dataset = create_datasets(df)\n",
    "\n",
    "print(\"Data loaded and datasets created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run training/prediction scripts\n",
    "def run_script(script_name, args_dict, mode='train_test'):\n",
    "    cmd = [\"python\", script_name, \"--mode\", mode]\n",
    "    for key, value in args_dict.items():\n",
    "        cmd.append(f\"--{key}\")\n",
    "        if isinstance(value, list):\n",
    "            cmd.extend([str(item) for item in value])\n",
    "        else:\n",
    "            cmd.append(str(value))\n",
    "\n",
    "    print(f\"\\nRunning command: {\' \".join(cmd)}\")\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    stdout, stderr = process.communicate()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Error running {script_name}:\")\n",
    "        print(stderr)\n",
    "        raise RuntimeError(f\"Script {script_name} failed with exit code {process.returncode}\")\n",
    "    else:\n",
    "        print(f\"Successfully ran {script_name}\")\n",
    "        print(stdout)\n",
    "    \n",
    "    return stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train and Evaluate TFT\n",
    "display(Markdown(\"## 3. Train and Evaluate Temporal Fusion Transformer (TFT)\"))\n",
    "\n",
    "tft_args = {\n",
    "    \"data\": DATA_PATH,\n",
    "    \"region\": REGION,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"hidden_size\": 64,\n",
    "    \"attention_heads\": 4\n",
    "}\n",
    "\n",
    "print(\"Training TFT model...\")\n",
    "tft_train_output = run_script(\"train_tft.py\", tft_args, mode=\"train_test\")\n",
    "\n",
    "# Extract checkpoint path from output\n",
    "tft_checkpoint_path = None\n",
    "for line in tft_train_output.splitlines():\n",
    "    if \"Best model:\" in line:\n",
    "        tft_checkpoint_path = line.split(\"Best model:\")[1].strip()\n",
    "        break\n",
    "\n",
    "if tft_checkpoint_path:\n",
    "    print(f\"TFT Best Checkpoint: {tft_checkpoint_path}\")\n",
    "    display(Markdown(\"### TFT Predictions\"))\n",
    "    tft_predict_args = {\n",
    "        \"checkpoint\": tft_checkpoint_path,\n",
    "        \"n_samples\": 3 # Plot fewer samples in notebook\n",
    "    }\n",
    "    tft_predict_output = run_script(\"predict_tft.py\", tft_predict_args, mode=\"test\")\n",
    "else:\n",
    "    print(\"Could not find TFT checkpoint path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train and Evaluate N-BEATS\n",
    "display(Markdown(\"## 4. Train and Evaluate N-BEATS\"))\n",
    "\n",
    "nbeats_args = {\n",
    "    \"data\": DATA_PATH,\n",
    "    \"region\": REGION,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"stack_types\": [\"seasonality\", \"trend\", \"identity\"],\n",
    "    \"num_blocks\": [3, 3, 3],\n",
    "    \"num_layers\": [4, 4, 4],\n",
    "    \"widths\": [256, 256, 256]\n",
    "}\n",
    "\n",
    "print(\"Training N-BEATS model...\")\n",
    "nbeats_train_output = run_script(\"train_nbeats.py\", nbeats_args, mode=\"train_test\")\n",
    "\n",
    "# Extract checkpoint path from output\n",
    "nbeats_checkpoint_path = None\n",
    "for line in nbeats_train_output.splitlines():\n",
    "    if \"Best model:\" in line:\n",
    "        nbeats_checkpoint_path = line.split(\"Best model:\")[1].strip()\n",
    "        break\n",
    "\n",
    "if nbeats_checkpoint_path:\n",
    "    print(f\"N-BEATS Best Checkpoint: {nbeats_checkpoint_path}\")\n",
    "    display(Markdown(\"### N-BEATS Predictions\"))\n",
    "    nbeats_predict_args = {\n",
    "        \"checkpoint\": nbeats_checkpoint_path,\n",
    "        \"n_samples\": 3\n",
    "    }\n",
    "    nbeats_predict_output = run_script(\"predict_nbeats.py\", nbeats_predict_args, mode=\"test\")\n",
    "else:\n",
    "    print(\"Could not find N-BEATS checkpoint path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train and Evaluate Informer\n",
    "display(Markdown(\"## 5. Train and Evaluate Informer\"))\n",
    "\n",
    "informer_args = {\n",
    "    \"data\": DATA_PATH,\n",
    "    \"region\": REGION,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_heads\": 4,\n",
    "    \"num_encoder_layers\": 2,\n",
    "    \"num_decoder_layers\": 1\n",
    "}\n",
    "\n",
    "print(\"Training Informer model...\")\n",
    "informer_train_output = run_script(\"train_informer.py\", informer_args, mode=\"train_test\")\n",
    "\n",
    "# Extract checkpoint path from output\n",
    "informer_checkpoint_path = None\n",
    "for line in informer_train_output.splitlines():\n",
    "    if \"Best model:\" in line:\n",
    "        informer_checkpoint_path = line.split(\"Best model:\")[1].strip()\n",
    "        break\n",
    "\n",
    "if informer_checkpoint_path:\n",
    "    print(f\"Informer Best Checkpoint: {informer_checkpoint_path}\")\n",
    "    display(Markdown(\"### Informer Predictions\"))\n",
    "    informer_predict_args = {\n",
    "        \"checkpoint\": informer_checkpoint_path,\n",
    "        \"n_samples\": 3\n",
    "    }\n",
    "    informer_predict_output = run_script(\"predict_informer.py\", informer_predict_args, mode=\"test\")\n",
    "else:\n",
    "    print(\"Could not find Informer checkpoint path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train and Evaluate DeepAR\n",
    "display(Markdown(\"## 6. Train and Evaluate DeepAR\"))\n",
    "\n",
    "deepar_args = {\n",
    "    \"data\": DATA_PATH,\n",
    "    \"region\": REGION,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"hidden_size\": 64,\n",
    "    \"rnn_layers\": 2\n",
    "}\n",
    "\n",
    "print(\"Training DeepAR model...\")\n",
    "deepar_train_output = run_script(\"train_deepar.py\", deepar_args, mode=\"train_test\")\n",
    "\n",
    "# Extract checkpoint path from output\n",
    "deepar_checkpoint_path = None\n",
    "for line in deepar_train_output.splitlines():\n",
    "    if \"Best model:\" in line:\n",
    "        deepar_checkpoint_path = line.split(\"Best model:\")[1].strip()\n",
    "        break\n",
    "\n",
    "if deepar_checkpoint_path:\n",
    "    print(f\"DeepAR Best Checkpoint: {deepar_checkpoint_path}\")\n",
    "    display(Markdown(\"### DeepAR Predictions\"))\n",
    "    deepar_predict_args = {\n",
    "        \"checkpoint\": deepar_checkpoint_path,\n",
    "        \"n_samples\": 3\n",
    "    }\n",
    "    deepar_predict_output = run_script(\"predict_deepar.py\", deepar_predict_args, mode=\"test\")\n",
    "else:\n",
    "    print(\"Could not find DeepAR checkpoint path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Summarize Results (Placeholder)\n",
    "display(Markdown(\"## 7. Model Comparison Summary\"))\n",
    "\n",
    "print(\"Metrics and plots will be displayed above for each model.\")\n",
    "print(\"Further analysis (e.g., summary tables, comparative plots) can be added here.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
